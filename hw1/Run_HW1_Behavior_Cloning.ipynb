{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run_HW1_Behavior_Cloning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jprussoibanez/homework_fall2019/blob/google_colab/hw1/Run_HW1_Behavior_Cloning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw1Ci-0Q_UUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3aCHljO-hCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from cs285.infrastructure.rl_trainer import RL_Trainer\n",
        "from cs285.agents.bc_agent import BCAgent\n",
        "from cs285.policies.loaded_gaussian_policy import Loaded_Gaussian_Policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy6iRABY_EFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BC_Trainer(object):\n",
        "\n",
        "    def __init__(self, params):\n",
        "\n",
        "        #######################\n",
        "        ## AGENT PARAMS\n",
        "        #######################\n",
        "\n",
        "        agent_params = {\n",
        "            'n_layers': params['n_layers'],\n",
        "            'size': params['size'],\n",
        "            'learning_rate': params['learning_rate'],\n",
        "            'max_replay_buffer_size': params['max_replay_buffer_size'],\n",
        "            }\n",
        "\n",
        "        self.params = params\n",
        "        self.params['agent_class'] = BCAgent ## TODO: look in here and implement this\n",
        "        self.params['agent_params'] = agent_params\n",
        "\n",
        "        ################\n",
        "        ## RL TRAINER\n",
        "        ################\n",
        "\n",
        "        self.rl_trainer = RL_Trainer(self.params) ## TODO: look in here and implement this\n",
        "\n",
        "        #######################\n",
        "        ## LOAD EXPERT POLICY\n",
        "        #######################\n",
        "\n",
        "        print('Loading expert policy from...', self.params['expert_policy_file'])\n",
        "        self.loaded_expert_policy = Loaded_Gaussian_Policy(self.rl_trainer.sess, self.params['expert_policy_file'])\n",
        "        print('Done restoring expert policy...')\n",
        "\n",
        "    def run_training_loop(self):\n",
        "\n",
        "        self.rl_trainer.run_training_loop(\n",
        "            n_iter=self.params['n_iter'],\n",
        "            initial_expertdata=self.params['expert_data'],\n",
        "            collect_policy=self.rl_trainer.agent.actor,\n",
        "            eval_policy=self.rl_trainer.agent.actor,\n",
        "            relabel_with_expert=self.params['do_dagger'],\n",
        "            expert_policy=self.loaded_expert_policy,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a092lz3R_G3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--expert_policy_file', '-epf', type=str, required=True)  # relative to where you're running this script from\n",
        "    parser.add_argument('--expert_data', '-ed', type=str, required=True) #relative to where you're running this script from\n",
        "    parser.add_argument('--env_name', '-env', type=str, help='choices: Ant-v2, Humanoid-v2, Walker-v2, HalfCheetah-v2, Hopper-v2', required=True)\n",
        "    parser.add_argument('--exp_name', '-exp', type=str, default='pick an experiment name', required=True)\n",
        "    parser.add_argument('--do_dagger', action='store_true')\n",
        "    parser.add_argument('--ep_len', type=int)\n",
        "\n",
        "    parser.add_argument('--num_agent_train_steps_per_iter', type=int, default=1000)  # number of gradient steps for training policy (per iter in n_iter)\n",
        "    parser.add_argument('--n_iter', '-n', type=int, default=1)\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=1000)  # training data collected (in the env) during each iteration\n",
        "    parser.add_argument('--eval_batch_size', type=int,\n",
        "                        default=200)  # eval data collected (in the env) for logging metrics\n",
        "    parser.add_argument('--train_batch_size', type=int,\n",
        "                        default=100)  # number of sampled data points to be used per gradient/train step\n",
        "\n",
        "    parser.add_argument('--n_layers', type=int, default=2)  # depth, of policy to be learned\n",
        "    parser.add_argument('--size', type=int, default=64)  # width of each layer, of policy to be learned\n",
        "    parser.add_argument('--learning_rate', '-lr', type=float, default=5e-3)  # LR for supervised learning\n",
        "\n",
        "    parser.add_argument('--video_log_freq', type=int, default=5)\n",
        "    parser.add_argument('--scalar_log_freq', type=int, default=1)\n",
        "    parser.add_argument('--use_gpu', action='store_true')\n",
        "    parser.add_argument('--which_gpu', type=int, default=0)\n",
        "    parser.add_argument('--max_replay_buffer_size', type=int, default=1000000)\n",
        "    parser.add_argument('--seed', type=int, default=1)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # convert args to dictionary\n",
        "    params = vars(args)\n",
        "\n",
        "    ##################################\n",
        "    ### CREATE DIRECTORY FOR LOGGING\n",
        "    ##################################\n",
        "\n",
        "    logdir_prefix = 'bc_'\n",
        "    if args.do_dagger:\n",
        "        logdir_prefix = 'dagger_'\n",
        "        assert args.n_iter>1, ('DAGGER needs more than 1 iteration (n_iter>1) of training, to iteratively query the expert and train (after 1st warmstarting from behavior cloning).')\n",
        "    else:\n",
        "        assert args.n_iter==1, ('Vanilla behavior cloning collects expert data just once (n_iter=1)')\n",
        "\n",
        "    ## directory for logging\n",
        "    data_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), '../data')\n",
        "    if not (os.path.exists(data_path)):\n",
        "        os.makedirs(data_path)\n",
        "    logdir = logdir_prefix + args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "    logdir = os.path.join(data_path, logdir)\n",
        "    params['logdir'] = logdir\n",
        "    if not(os.path.exists(logdir)):\n",
        "        os.makedirs(logdir)\n",
        "\n",
        "\n",
        "    ###################\n",
        "    ### RUN TRAINING\n",
        "    ###################\n",
        "\n",
        "    trainer = BC_Trainer(params)\n",
        "    trainer.run_training_loop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdWfLvP_PFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}